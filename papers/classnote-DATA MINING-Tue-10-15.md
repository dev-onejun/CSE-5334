$$
\begin{array}{|c|c|}
\hline
\text{} & \text{} \\
\hline
\text{} & \text{} \\
\hline
\end{array}
$$

### Evaluation of Classification

Overfitting
- .
- Due to noise
- lack of data (insufficient variety features of data)

    * Solution
        - Pre-Pruning (Early Stop)
            ex. Stop before the tree becomes a fully-glown
            ex. ..
            ex. kai^2 test?
        - Post-Pruning
            in example. if child node has low error, do not prune (post-pruning in decision tree)


Underfitting
- .


* Oscam's Razor
- The simpler model is better than the complex model if both models have the same performance
    * MDL?



* Handling Missing Attribute Values
- Computing Impurity Measure
- Distribute Instances
- Classify Instances

* Data Fragmentation, Search Strategy, Expressiveness, Tree Replication
























### References

$\tag*{}\label{n} \text{[n] }$
