{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "041f62a4-519e-4f8a-aae2-1e457f634a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.643\n",
      "Confusion Matrix\n",
      "Predicted    C   PF   PG   SF   SG  All\n",
      "Actual                                 \n",
      "C          110   15    0    2    2  129\n",
      "PF          30   69    4   27    8  138\n",
      "PG           1    3  101    4   25  134\n",
      "SF           5   30    9   60   27  131\n",
      "SG           0   11   21   20  100  152\n",
      "All        146  128  135  113  162  684\n",
      "Model: adaboost\n",
      "Validate set accuracy: 0.579\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          23   5   0   1   0   29\n",
      "PF         11  18   0   7   5   41\n",
      "PG          0   0  18   4  10   32\n",
      "SF          1   4   1  18   5   29\n",
      "SG          0   4   3  11  22   40\n",
      "All        35  31  22  41  42  171\n",
      "Model: adaboost2\n",
      "Validate set accuracy: 0.579\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          27   2   0   0   0   29\n",
      "PF         10  17   2  10   2   41\n",
      "PG          0   0  19   3  10   32\n",
      "SF          1   2   3  18   5   29\n",
      "SG          0   5   7  10  18   40\n",
      "All        38  26  31  41  35  171\n",
      "Model: adaboost3\n",
      "Validate set accuracy: 0.596\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          26   3   0   0   0   29\n",
      "PF          9  19   1   9   3   41\n",
      "PG          0   0  17   3  12   32\n",
      "SF          1   6   2  16   4   29\n",
      "SG          0   5   1  10  24   40\n",
      "All        36  33  21  38  43  171\n",
      "Model: randomforest\n",
      "Validate set accuracy: 0.573\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          25   3   0   1   0   29\n",
      "PF         11  11   1  13   5   41\n",
      "PG          0   0  29   0   3   32\n",
      "SF          0   5   3   9  12   29\n",
      "SG          0   6   7   3  24   40\n",
      "All        36  25  40  26  44  171\n",
      "Model: svm\n",
      "Validate set accuracy: 0.626\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          24   5   0   0   0   29\n",
      "PF          7  21   2   9   2   41\n",
      "PG          0   1  30   0   1   32\n",
      "SF          1  10   1  10   7   29\n",
      "SG          0   9   6   3  22   40\n",
      "All        32  46  39  22  32  171\n",
      "Model: logistic\n",
      "Validate set accuracy: 0.602\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          27   2   0   0   0   29\n",
      "PF         11  17   1   9   3   41\n",
      "PG          0   0  29   0   3   32\n",
      "SF          2   5   1   7  14   29\n",
      "SG          0   4   7   6  23   40\n",
      "All        40  28  38  22  43  171\n",
      "Model: knn2\n",
      "Validate set accuracy: 0.556\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          24   5   0   0   0   29\n",
      "PF          9  10   2  12   8   41\n",
      "PG          0   0  27   1   4   32\n",
      "SF          1   3   1  11  13   29\n",
      "SG          0   4   8   5  23   40\n",
      "All        34  22  38  29  48  171\n",
      "Model: knn3\n",
      "Validate set accuracy: 0.591\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          24   4   0   1   0   29\n",
      "PF         10  13   0  11   7   41\n",
      "PG          0   0  24   1   7   32\n",
      "SF          0   3   0  12  14   29\n",
      "SG          1   3   2   6  28   40\n",
      "All        35  23  26  31  56  171\n",
      "Model: knn6\n",
      "Validate set accuracy: 0.591\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          24   4   0   1   0   29\n",
      "PF         10  15   1   7   8   41\n",
      "PG          0   0  27   0   5   32\n",
      "SF          1   2   1  13  12   29\n",
      "SG          0   3   5  10  22   40\n",
      "All        35  24  34  31  47  171\n",
      "Model: gradient_boosting\n",
      "Validate set accuracy: 0.567\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          23   6   0   0   0   29\n",
      "PF         12  11   2  11   5   41\n",
      "PG          0   0  26   0   6   32\n",
      "SF          0   4   2  13  10   29\n",
      "SG          0   2   7   7  24   40\n",
      "All        35  23  37  31  45  171\n",
      "Model: naive_bayes\n",
      "Validate set accuracy: 0.433\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          23   6   0   0   0   29\n",
      "PF          8  21   2   7   3   41\n",
      "PG          0   7   6   4  15   32\n",
      "SF          1  12   5   6   5   29\n",
      "SG          0   9   7   6  18   40\n",
      "All        32  55  20  23  41  171\n",
      "Model: extra_trees\n",
      "Validate set accuracy: 0.608\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          26   2   0   1   0   29\n",
      "PF         11  14   1  11   4   41\n",
      "PG          0   0  28   0   4   32\n",
      "SF          0   4   2  10  13   29\n",
      "SG          0   3   7   4  26   40\n",
      "All        37  23  38  26  47  171\n",
      "Model: xgboost\n",
      "Validate set accuracy: 0.591\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          25   2   0   2   0   29\n",
      "PF         12   9   1  14   5   41\n",
      "PG          0   0  27   0   5   32\n",
      "SF          0   3   2  14  10   29\n",
      "SG          0   3   7   4  26   40\n",
      "All        37  17  37  34  46  171\n",
      "Model: mlpc1\n",
      "Validate set accuracy: 0.673\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          28   0   1   0   0   29\n",
      "PF         12  15   0  11   3   41\n",
      "PG          0   0  31   0   1   32\n",
      "SF          0   5   1  15   8   29\n",
      "SG          0   2   6   6  26   40\n",
      "All        40  22  39  32  38  171\n",
      "Model: decision_tree\n",
      "Validate set accuracy: 0.532\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          23   5   0   0   1   29\n",
      "PF         11  14   1  10   5   41\n",
      "PG          1   0  22   2   7   32\n",
      "SF          1   3   1  17   7   29\n",
      "SG          4   0   5  16  15   40\n",
      "All        40  22  29  45  35  171\n",
      "Model: mlpc2\n",
      "Validate set accuracy: 0.643\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          24   4   1   0   0   29\n",
      "PF         10  21   1   8   1   41\n",
      "PG          0   0  29   0   3   32\n",
      "SF          0   8   1  11   9   29\n",
      "SG          0   2   6   7  25   40\n",
      "All        34  35  38  26  38  171\n",
      "Model: mlpc3\n",
      "Validate set accuracy: 0.637\n",
      "Confusion Matrix\n",
      "Predicted   C  PF  PG  SF  SG  All\n",
      "Actual                            \n",
      "C          27   2   0   0   0   29\n",
      "PF         10  18   1  10   2   41\n",
      "PG          0   0  29   0   3   32\n",
      "SF          0   8   1   9  11   29\n",
      "SG          0   4   6   4  26   40\n",
      "All        37  32  37  23  42  171\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from scipy.spatial.distance import canberra\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Set seed for reproducibility\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def load_data(path) -> tuple:\n",
    "    \"\"\"\n",
    "    Load data from the given path and return the features and labels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : pd.DataFrame - features of the data to be used for training\n",
    "    y_encoded : np.ndarray - encoded labels of the data to be used for training\n",
    "    label_encoder : LabelEncoder - label encoder used to encode and decode the labels\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path)  # 27 features\n",
    "\n",
    "    X = data.drop(\n",
    "        columns=[\"Pos\", \"Tm\", \"G\", \"GS\", \"FG%\", \"3P%\", \"FT%\", \"PTS\"]\n",
    "    )  # 19 features\n",
    "    y = data[\"Pos\"]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    X[[\"AST\", \"BLK\"]] *= 10\n",
    "\n",
    "    return X, y_encoded, label_encoder\n",
    "\n",
    "\n",
    "def correlation_distance(x, y):\n",
    "    return 1 - np.corrcoef(x, y)[0, 1]\n",
    "\n",
    "\n",
    "def canberra_distance(x, y):\n",
    "    return canberra(x, y)\n",
    "\n",
    "\n",
    "def chi_square_distance(x, y):\n",
    "    return 0.5 * np.sum((x - y) ** 2 / (x + y + 1e-10))\n",
    "\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "X, y_encoded, label_encoder = load_data(\"./nba_stats.csv\")\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(\n",
    "    X, y_encoded, train_size=0.8, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "models = train_model(X_train, y_train, label_encoder)\n",
    "evaluate_each_model(models, X_validate, y_validate, label_encoder, \"Validate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b798d6e-724a-4f54-9cd1-e0a065b6e4eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667bd649-934d-42e6-9f5d-c1f465008077",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['ORB', 'BLK', '3PA', 'TRB', '3P', 'FG%', '3P%', 'DRB', '2P%', 'STL', 'PF', 'eFG%', '2P', 'AST', 'FGA', 'FT%', 'MP', '2PA', 'PTS', 'Age']\n",
    "X = data[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656c0954-13cf-4cb2-992c-e4fb56e0dcfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245b6848-e570-4aa9-8468-f21c82b01336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hyperparameters(X_train, y_train):\n",
    "    \"\"\"Gradient Boosting Grid Search\n",
    "    ada_params = {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 1.0],\n",
    "        \"estimator\": [\n",
    "            DecisionTreeClassifier(max_depth=1),\n",
    "            DecisionTreeClassifier(max_depth=2),\n",
    "        ],\n",
    "        \"algorithm\": [\"SAMME\", \"SAMME.R\"],\n",
    "        \"random_state\": [RANDOM_STATE],\n",
    "    }\n",
    "    ada_grid = GridSearchCV(\n",
    "        AdaBoostClassifier(random_state=RANDOM_STATE), ada_params, scoring=\"accuracy\"\n",
    "    )\n",
    "    ada_grid.fit(X_train, y_train)\n",
    "    best_ada = ada_grid.best_estimator_\n",
    "    print(\"Best AdaBoost Parameters:\", ada_grid.best_params_)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" Random Forest Grid Search\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "    }\n",
    "    grid_search = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=RANDOM_STATE), param_grid\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    print(best_rf)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" SVM Grid Search\n",
    "    svm_params = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'kernel': ['linear', 'rbf', 'poly'],\n",
    "            'gamma': ['scale', 'auto', 0.01, 0.001]\n",
    "    }\n",
    "    svm_grid = GridSearchCV(SVC(probability=True, random_state=RANDOM_STATE), svm_params, scoring='accuracy')\n",
    "    svm_grid.fit(X_train, y_train)\n",
    "    best_svm = svm_grid.best_estimator_\n",
    "    print(\"Best SVM Parameters:\", svm_grid.best_params_)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" Gradient Boosting Grid Search\n",
    "    gb_params = {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.5],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"subsample\": [0.7, 0.8, 1.0],\n",
    "    }\n",
    "    gb_grid = GridSearchCV(\n",
    "        GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "        gb_params,\n",
    "        scoring=\"accuracy\",\n",
    "    )\n",
    "    gb_grid.fit(X_train, y_train)\n",
    "    best_gb = gb_grid.best_estimator_\n",
    "    print(\"Best Gradient Boosting Parameters:\", gb_grid.best_params_)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" KNN Grid Search\n",
    "    knn_params = {\n",
    "        'n_neighbors': [3, 5, 7, 10],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['minkowski'],\n",
    "        'p': [1, 2, 3, 10, 19]\n",
    "    }\n",
    "    knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, scoring='accuracy')\n",
    "    knn_grid.fit(X_train, y_train)\n",
    "    best_knn = knn_grid.best_estimator_\n",
    "    print(\"Best KNN Parameters:\", knn_grid.best_params_)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" XGBoost Grid Search\n",
    "    xgb_params = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.1, 0.3],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'subsample': [0.7, 0.8, 1.0]\n",
    "    }\n",
    "    xgb_grid = GridSearchCV(XGBClassifier(random_state=RANDOM_STATE, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "                                                    xgb_params, scoring='accuracy')\n",
    "    xgb_grid.fit(X_train, y_train)\n",
    "    best_xgb = xgb_grid.best_estimator_\n",
    "    print(\"Best XGBoost Parameters:\", xgb_grid.best_params_)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" Logistic Regression Grid Search\n",
    "    lr_params = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "            'solver': ['liblinear', 'saga']\n",
    "    }\n",
    "    lr_grid = GridSearchCV(LogisticRegression(random_state=RANDOM_STATE), lr_params, scoring='accuracy')\n",
    "    lr_grid.fit(X_train, y_train)\n",
    "    best_lr = lr_grid.best_estimator_\n",
    "    print(\"Best Logistic Regression Parameters:\", lr_grid.best_params_)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97068988-9918-4e09-b8c2-725db2dd847e",
   "metadata": {},
   "source": [
    "### Individual Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c7bb679-58b6-49fb-9f34-56bd05d7098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, label_encoder) -> dict:\n",
    "    \"\"\"\n",
    "    Train multiple models and return them in a dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pd.DataFrame - features of the data to be used for training\n",
    "    y_train : np.ndarray - encoded labels of the data to be used for training\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    models : dict - dictionary containing the trained models\n",
    "    \"\"\"\n",
    "    adaboost = AdaBoostClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=50,\n",
    "        learning_rate=1,\n",
    "    )\n",
    "    adaboost2 = AdaBoostClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=100,\n",
    "        learning_rate=1,\n",
    "    )\n",
    "    adaboost3 = AdaBoostClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=75,\n",
    "        learning_rate=1,\n",
    "    )\n",
    "    randomforest = RandomForestClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=50,\n",
    "        max_depth=10,\n",
    "        criterion=\"entropy\",\n",
    "        min_samples_leaf=2,\n",
    "        min_samples_split=10,\n",
    "    )\n",
    "    svm = SVC(random_state=RANDOM_STATE)\n",
    "    logistic = LogisticRegression(random_state=RANDOM_STATE)\n",
    "    knn2 = KNeighborsClassifier(\n",
    "        n_neighbors=10,\n",
    "        metric=correlation_distance,\n",
    "        weights=\"distance\",\n",
    "    )\n",
    "    knn3 = KNeighborsClassifier(\n",
    "        n_neighbors=10,\n",
    "        metric=canberra_distance,\n",
    "        weights=\"distance\",\n",
    "    )\n",
    "    knn6 = KNeighborsClassifier(\n",
    "        n_neighbors=10,\n",
    "        metric=chi_square_distance,\n",
    "        weights=\"distance\",\n",
    "    )\n",
    "    gradient_boosting = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "    naive_bayes = GaussianNB()\n",
    "    extra_trees = ExtraTreesClassifier(random_state=RANDOM_STATE)\n",
    "    xgboost = XGBClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        learning_rate=0.01,\n",
    "        max_depth=5,\n",
    "        n_estimators=200,\n",
    "        subsample=0.7,\n",
    "    )\n",
    "    mlpc1 = MLPClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        hidden_layer_sizes=(200),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        max_iter=400,\n",
    "        alpha=0.0001,\n",
    "        learning_rate=\"constant\",\n",
    "    )\n",
    "    decision_tree = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    mlpc2 = MLPClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        learning_rate_init=0.001,\n",
    "        hidden_layer_sizes=(150),\n",
    "        max_iter=400,\n",
    "        activation=\"tanh\",\n",
    "        solver=\"adam\",\n",
    "    )\n",
    "    mlpc3 = MLPClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        hidden_layer_sizes=(50, 50),\n",
    "        learning_rate_init=0.001,\n",
    "        activation=\"tanh\",\n",
    "        solver=\"sgd\",\n",
    "        max_iter=400,\n",
    "    )\n",
    "\n",
    "    models = {\n",
    "        \"adaboost\": adaboost,\n",
    "        \"adaboost2\": adaboost2,\n",
    "        \"adaboost3\": adaboost3,\n",
    "        \"randomforest\": randomforest,\n",
    "        \"svm\": svm,\n",
    "        \"logistic\": logistic,\n",
    "        \"knn2\": knn2,\n",
    "        \"knn3\": knn3,\n",
    "        \"knn6\": knn6,\n",
    "        \"gradient_boosting\": gradient_boosting,\n",
    "        \"naive_bayes\": naive_bayes,\n",
    "        \"extra_trees\": extra_trees,\n",
    "        \"xgboost\": xgboost,\n",
    "        \"mlpc1\": mlpc1,\n",
    "        \"decision_tree\": decision_tree,\n",
    "        \"mlpc2\": mlpc2,\n",
    "        \"mlpc3\": mlpc3,\n",
    "    }\n",
    "\n",
    "    for model in models.values():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    # find_hyperparameters(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_train)\n",
    "    \n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "    print(f\"Training set accuracy: %.3f\" % accuracy)\n",
    "\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(\n",
    "        pd.crosstab(\n",
    "            label_encoder.inverse_transform(y_train),\n",
    "            label_encoder.inverse_transform(y_pred),\n",
    "            rownames=[\"Actual\"],\n",
    "            colnames=[\"Predicted\"],\n",
    "            margins=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfafe572-d5a3-4797-8654-c2d6e2973070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_each_model(models, X_validate, y_validate, label_encoder, data_type):\n",
    "    \"\"\"\n",
    "    Evaluate each model with the validation set and print the accuracy and classification report\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models : dict - dictionary containing the trained models\n",
    "    X_validate : pd.DataFrame - features of the data to be used for validation\n",
    "    y_validate : np.ndarray - encoded labels of the data to be used for validation\n",
    "    label_encoder : LabelEncoder - label encoder used to encode and decode the labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_validate)\n",
    "\n",
    "        accuracy = accuracy_score(y_validate, y_pred)\n",
    "        report = classification_report(\n",
    "            y_validate, y_pred, target_names=label_encoder.classes_\n",
    "        )\n",
    "\n",
    "        print(f\"Model: {name}\")\n",
    "        print(f\"{data_type} set accuracy: %.3f\" % accuracy)\n",
    "\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(\n",
    "            pd.crosstab(\n",
    "                label_encoder.inverse_transform(y_validate),\n",
    "                label_encoder.inverse_transform(y_pred),\n",
    "                rownames=[\"Actual\"],\n",
    "                colnames=[\"Predicted\"],\n",
    "                margins=True,\n",
    "            )\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
